{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6847805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear, CrossEntropyLoss, Sequential, Softmax\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8afc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32799306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = iris['data']\n",
    "y_data = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7024cb5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc823c4c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)[y_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7321b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor( x_data )\n",
    "y = torch.FloatTensor( np.eye(3)[y_data] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f01d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add_module( 'nn1', Linear(4,3) ) # w:2x3, b:3 \n",
    "model.add_module( 'soft1', Softmax(dim=1) ) #활성함수.\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = Adam( model.parameters(), lr=0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dfd1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1486551761627197\n",
      "1 1.1053948402404785\n",
      "2 1.0744383335113525\n",
      "3 1.0290894508361816\n",
      "4 1.0070520639419556\n",
      "5 0.9625884890556335\n",
      "6 0.9217512011528015\n",
      "7 0.9020153880119324\n",
      "8 0.8777413964271545\n",
      "9 0.8488017320632935\n",
      "10 0.8270640969276428\n",
      "11 0.821597158908844\n",
      "12 0.8075140118598938\n",
      "13 0.789858877658844\n",
      "14 0.7853644490242004\n",
      "15 0.776793897151947\n",
      "16 0.7647414207458496\n",
      "17 0.7633049488067627\n",
      "18 0.7549611330032349\n",
      "19 0.7465090155601501\n",
      "20 0.7441757917404175\n",
      "21 0.7359281182289124\n",
      "22 0.7297661900520325\n",
      "23 0.7272564768791199\n",
      "24 0.7197781205177307\n",
      "25 0.7158327102661133\n",
      "26 0.7124631404876709\n",
      "27 0.7060925364494324\n",
      "28 0.7028628587722778\n",
      "29 0.6990960240364075\n",
      "30 0.6938748955726624\n",
      "31 0.6913173198699951\n",
      "32 0.6876012682914734\n",
      "33 0.6836045980453491\n",
      "34 0.6814138293266296\n",
      "35 0.6779609322547913\n",
      "36 0.67487633228302\n",
      "37 0.6727834343910217\n",
      "38 0.6697146892547607\n",
      "39 0.6672357320785522\n",
      "40 0.6653110980987549\n",
      "41 0.6627161502838135\n",
      "42 0.660747766494751\n",
      "43 0.6590090990066528\n",
      "44 0.6568337082862854\n",
      "45 0.6551559567451477\n",
      "46 0.6535668969154358\n",
      "47 0.6517001986503601\n",
      "48 0.6502402424812317\n",
      "49 0.64881432056427\n",
      "50 0.6472306847572327\n",
      "51 0.645954966545105\n",
      "52 0.6446862816810608\n",
      "53 0.6433103680610657\n",
      "54 0.6421586871147156\n",
      "55 0.6410056352615356\n",
      "56 0.639786958694458\n",
      "57 0.6387392282485962\n",
      "58 0.637700617313385\n",
      "59 0.6366218328475952\n",
      "60 0.6356703042984009\n",
      "61 0.6347290277481079\n",
      "62 0.6337582468986511\n",
      "63 0.6328800320625305\n",
      "64 0.6320171356201172\n",
      "65 0.6311357617378235\n",
      "66 0.6303261518478394\n",
      "67 0.6295368671417236\n",
      "68 0.6287367939949036\n",
      "69 0.6279898285865784\n",
      "70 0.6272640228271484\n",
      "71 0.6265310049057007\n",
      "72 0.6258374452590942\n",
      "73 0.6251653432846069\n",
      "74 0.6244907975196838\n",
      "75 0.623846709728241\n",
      "76 0.6232243180274963\n",
      "77 0.6226025223731995\n",
      "78 0.6220037937164307\n",
      "79 0.6214249730110168\n",
      "80 0.6208487749099731\n",
      "81 0.6202899217605591\n",
      "82 0.6197493076324463\n",
      "83 0.6192134022712708\n",
      "84 0.6186909675598145\n",
      "85 0.6181851029396057\n",
      "86 0.6176854372024536\n",
      "87 0.6171964406967163\n",
      "88 0.616722047328949\n",
      "89 0.6162543892860413\n",
      "90 0.6157954335212708\n",
      "91 0.6153490543365479\n",
      "92 0.6149099469184875\n",
      "93 0.6144782304763794\n",
      "94 0.6140575408935547\n",
      "95 0.6136443018913269\n",
      "96 0.613237738609314\n",
      "97 0.6128405332565308\n",
      "98 0.6124507784843445\n",
      "99 0.6120669841766357\n",
      "100 0.6116911768913269\n",
      "101 0.6113226413726807\n",
      "102 0.6109596490859985\n",
      "103 0.6106036305427551\n",
      "104 0.6102544665336609\n",
      "105 0.6099106073379517\n",
      "106 0.6095729470252991\n",
      "107 0.6092415452003479\n",
      "108 0.6089153289794922\n",
      "109 0.6085945963859558\n",
      "110 0.6082795858383179\n",
      "111 0.6079695820808411\n",
      "112 0.6076644659042358\n",
      "113 0.6073645949363708\n",
      "114 0.6070695519447327\n",
      "115 0.6067790389060974\n",
      "116 0.606493353843689\n",
      "early stop\n"
     ]
    }
   ],
   "source": [
    "patience = 100\n",
    "min_delta = 0.01\n",
    "hist_cost = []\n",
    "pcnt= 0\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    hx = model(x)\n",
    "    c = loss_fn( hx, y ) \n",
    "    c.backward()\n",
    "    optimizer.step()\n",
    "    hist_cost.append( c.item() )\n",
    "    print( epoch, c.item() )\n",
    "    if epoch > 0:\n",
    "        if hist_cost[epoch-1] - hist_cost[epoch] > min_delta:\n",
    "            pcnt= 0\n",
    "        else:\n",
    "            pcnt +=1\n",
    "        if pcnt >= patience:\n",
    "            print('early stop')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a765e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e60eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
